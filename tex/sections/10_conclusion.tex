\chapter{Conclusion}\label{chap:conclusion}
We have now reached the end of the journey into the theory, calibration and simulation of readout in a superconducting system.  To end this thesis, we will summarize the key points before looking at some possible next steps for this project.

To create a model of superconducting qubit readout, we have reviewed the theory behind it in three stages. The unitary evolution of the system, where we described how the coupling between qubit and resonator allow us to measure the qubit by driving the resonator. The interaction with the environment, where we have described the challenges of a qubit and resonator that loses coherence or exchange energy with the environment. And finally, the stochastic evolution which describes the unraveling of a single trajectory. The review of theory have given us the tools for simulating the dynamics and a list of parameters which we need to determine to make a realistic model.

Following the list of parameters, we have performed a sequence of calibrations leading a list of estimated parameters to enter the simulation model. By running the model and comparing to the readout sequence experiment from the laboratory, we conclude that we get a similar state initialization and measurement fidelity. While the distributions also look promisingly, they are not perfectly convincing. This hints that X-gate fidelity and the second excited state should be included in the analysis. 

By changing parameters to the ideal values, we used the realistic model to estimate the contributions from three different sources to the SPAM infidelity. We find for our system and a $600 \text{ ns}$ readout pulse that the primary contributor to infidelity is a high temperature, followed by a low efficiency and low coherence time. Lastly, we have used the model to estimate the improvements to the SPAM-fidelity by marginal improvements in efficiency, temperature or coherence time. These estimates were used to enter a discussion of how different strategies to the initialization and readout sequence can be used to reduce the impact of low efficiency, high temperature or low coherence given that the other parameters are better. 


\section{Next Steps}
During the learning, writing and coding  for thesis thesis, my overview of the field and the methods have developed significantly. Of course, this means that looking back at the w, there are many things I would have liked to do differently, in another order or maybe should not have shelved. With the overview multiple paths have also presented themselves as the continuation of this work. In addition to model optimization and inclusion of smaller details, this last part of the thesis will cover a short presentation of the next steps.

\subsection{Fitting the Model to Trajectories}
In this thesis, the model was made by calibrating the qubit using different methods for each parameter. Instead, we could explorer if the model could be directly fitted to the data to retrieve the calibrated parameters. We saw in figure \ref{trajectories_and_qfunc} that convolving the q-function with a Gaussian, we get a good estimate for distribution of the readout record at a given time. One could imagine using this to calculate the log.likelihood of each point at each time given a set of parameters. If we consider this a cost function, we can leverage the development of ODE integration techniques in deep learning libraries. This allow us to maximize the likelihood by tuning the parameters, where the gradients can be found by either autograd methods or by the adjoint state method. \cite{allaire}

New libraries for minimizing stochastic differential equation models have also been developed and are now already used to calibrate qubit parameters \cite{genois_quantum-tailored_2021}. In this work, the set of equation from section \ref{sec:qubit_backaction} was used to only run the simulation in a two dimensional Hilbert space where the resonator was averaged out. One could imagine reintroducing the resonator with the models presented in this thesis.


\subsection{Including Improved Strategies in Simulation} 
In chapter \ref{chap:budget} we discussed different strategies to swap good performing variables for others. It would definitely be beneficial to include these strategies in simulation. First, the amplitude and duration of the pulse should be optimized in the realistic setting before good estimates for improved devices can be extracted. The next steps will be to include $\ket{1}\to\ket{2}$ pulses as well as active reset. This would allow for a more flexible model that does not slack a few steps behind what is happening at the fridge. 

\subsection{Bigger Hilbert Space - High Power Simulations}
Lastly, we have been limited in our readout power, not by the quantum device in question, but by classical computation power used to run the simulation. By having more computational resources (and time) it would be possible to also drive the resonator to a mean photon number of $\approx30$ or maybe even higher. This would give a better illustration of what is happening in the laboratory. Of course, we will need to check the dispersive approximation thoroughly when we start to add more photons.   