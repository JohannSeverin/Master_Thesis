\chapter{Conclusion}\label{chap:conclusion}
We have now reached the end of the journey into the theory, calibration and simulation of readout in a superconducting system.  To end this thesis, we will summarize the key points before looking at some possible next steps for this project.

To create a model of superconducting qubit readout, we have reviewed the theory behind it in three stages. The unitary evolution of the system, where we described how the coupling between qubit and resonator allow us to measure the qubit by driving the resonator. The interaction with the environment, where we have described the challenges of a qubit and resonator that loses coherence or exchange energy with the environment. And finally, the stochastic evolution which describes the unraveling of a single trajectory subject to weak measurements. The review of theory have given us the tools for simulating the dynamics and a list of parameters which we need to determine to make a realistic model.

Following the list of parameters, we have performed a sequence of calibrations leading to a list of estimated parameters to enter the simulation model. By running the model and comparing to the readout sequence experiment from the laboratory, we conclude that we get a similar state initialization and measurement fidelity. While the distributions also look promisingly, they are not overwhelmingly convincing. This hints that X-gate fidelity and the second excited state should be included in the analysis. 

By changing parameters to the ideal values, we used the realistic model to estimate the contributions from three different sources to the SPAM infidelity. We find for our system and a $600 \text{ ns}$ readout pulse that the primary contributor to infidelity is a high temperature, followed by a low efficiency and low coherence time. Lastly, we have used the model to estimate the improvements to the SPAM-fidelity by marginal improvements in efficiency, temperature or coherence time. These estimates were used to enter a discussion of how different strategies to the initialization and readout sequence can be used to reduce the impact of low efficiency, high temperature or low coherence given that the other parameters are better. 


\section{Next Steps}
During the learning, writing and coding  for this thesis, my overview of the field and the methods have increased significantly. Of course,  there are many things I would have liked to do differently, in another order or have shelved earlier if I look back now. However, this has also come with ideas for possible paths for continuing the work. While some are straight forward like general model optimization and inclusion of X-gate fidelity and qutrit dynamics, some require more work. The last part of this thesis will cover a short presentation of some possible continuations.

\subsection{Fitting the Model to Trajectories}
In this thesis, the model was made by calibrating the qubit using different methods for each parameter. Instead, we could explore if the model could be directly fitted to the data to retrieve the calibrated parameters. We saw in figure \ref{sec:trajectories_and_qfunc} that convolving the q-function with a Gaussian, we get a good estimate for the distribution of the readout record at a given time. One could imagine using this to calculate the log-likelihood of each point at each time given a set of parameters. If we consider this a cost function, we can leverage the development of ODE integration techniques in deep learning libraries. This allow us to maximize the likelihood by tuning the parameters, where the gradients can be found by either autograd methods or by the adjoint state method. \cite{allaire_review_2015}

New libraries for minimizing stochastic differential equation models have also been developed and are now already used to calibrate qubit parameters \cite{genois_quantum-tailored_2021}. Here the qubit is however modeled without the resonator with the equations from section \ref{sec:qubit_backaction}. One could imagine reintroducing the resonator with the models presented in this thesis to get an even better representation of the dynamics.


\subsection{Including Improved Strategies in Simulation} 
In chapter \ref{chap:budget}, we discussed different strategies to swap good performing variables for others. It would definitely be beneficial to include these strategies in simulation. First, the amplitude and duration of the pulse should be optimized in the realistic setting before good estimates for improved devices can be extracted. The next steps will be to include $\ket{1}\to\ket{2}$ pulses as well as active reset. This would allow for a more flexible model that does not slack a few steps behind what is happening at the fridge. 

\subsection{Bigger Hilbert Space - High Power Simulations}
Lastly, we have been limited in our readout power, not by the quantum device in question, but by classical computation power used to run the simulation. By having more computational resources (and time) it would be possible to also drive the resonator to a mean photon number of $\approx30$ or maybe even higher. This would give a better illustration of what is happening in the laboratory. Of course, we will need to check the dispersive approximation thoroughly when we start to add more photons.   