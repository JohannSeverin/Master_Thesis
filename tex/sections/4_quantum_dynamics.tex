\begin{fullwidth}
\chapter{Dynamics of Open Quantum Systems} \label{chap:open_quantum_systems}
\end{fullwidth}
Up untill now, we have considered the qubit and resonator as an isolated quantity. With no interaction with the environment, the system follows a unitary time evolution subject to the Schrödinger equation. Ideally, this would be the case, Unfortunately, the reality is that our devices interact with the environment and to properly determine its dynamics, we have to consider open quantum systems. \\


\section{Density Matrix Formalism}\label{sec:density_matrix_formalism}
First, we need to reformulate our representation of a quantum state. Up un till now, a state has been represented by at state vector $\ket{\psi}$, where the state can be superposition of states in some basis: $\ket{\psi} = \sum_i c_i\ket{\psi_i}$, where $c_i$ is the complex coefficient and the state is normalized such that $\sum |c_i|^2 = 1$. While this is a great formalism when you have knowledge about the entire system, it is not great at handling interactions with an unknown environment. In the density matrix formalism, we represent a single state of a quantum system, not as a vector, but by a matrix. We will here be following the nice introduction in \cite{manzano_short_2020}.

To describe an open system, we introduce the formalism of \textit{density matrices}. Taking a ket state in this formalism, we have a matrix of the form:
\begin{equation}
    \rho = \sum_i p_i \ket{i}\bra{i}
\end{equation}
where $p_i = |c_i|^2$ is the probability of finding the state $\ket{i}$ on measurement. Since the diagonal contains probabilities, we must have:
\begin{align}
    \Tr(\rho) &= 1 \\
    p_i &\geq 0
\end{align}
This is just a representation of a ket state, meaning that there would be some basis, where $p_x = 1$ and $p_i = 0$ for $i\neq x$. A density matrix, which has this property in a basis is called \textit{pure} since it can be represented by a ket. Since the trace is independent of basis, this gives a property of a pure density matrix\footnote{If it is not pure, it is still diagonalizeable, but will in this representation have multiple diagonal elements $<1$, so $\sum_i p_i^2 \neq 1$}:
\begin{equation}
    \Tr(\rho_{\text{pure}}^2) = 1
\end{equation}
The motivation behind introducing density matrices are when we do not have a pure state. An example could be two coupled two level systems. If we have the entangled states\footnote{The $\otimes$ references to the product state of two Hilbert spaces: $\mathcal{H}^2 \otimes \mathcal{H}^2$. Sometimes the $\otimes$ will be omitted and the state $\ket{1 1}$ will represent $\ket{1} \otimes \ket{1}$.}:

\begin{equation}\label{eq:phi_plus}
    \ket{\phi_+} = \fracsqrttwo(\ket{0}\otimes \ket{0} + \ket{1}\otimes\ket{1})
\end{equation}

Which in density matrix formalism will be:
\begin{equation}
    \rho_{\phi+} = 
    \begin{pmatrix}
        \frac{1}{2} & 0 & 0 & \frac{1}{2} \\
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 \\
        \frac{1}{2} & 0 & 0 & \frac{1}{2}
    \end{pmatrix}
\end{equation}
It can be seen that we now acquire non-diagonal terms. These are called coherences since they refer to the entanglement for the two states.  But this matrix is different from: 
\begin{equation}
    \rho = 
    \begin{pmatrix}
        \frac{1}{2} & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & \frac{1}{2}
    \end{pmatrix}
\end{equation}
where the coherences are $0$. Without the coherence elements, this is not an entangled superposition, but rather mean that the in an ensemble: half of the ensemble will be prepared in $\ket{00}$ and the other half in $\ket{11}$. \footnote{This fact can not be represented in the bra-ket notation that we are used to, and here lies the true power of the density matrix formalism: we quantify entanglement versus a fraction of populations.}
In general, we write the full density matrix as:
\begin{equation}
    \rho = \sum_{ij} \rho_{i,j} \ket{i}\bra{j}
\end{equation}

\subsection{Properties}
In matrices, some properties take a different form. Firstly, the expectation value $\expval{\psi} = \mel{\psi}{A}{\psi}$ is in the density matrix formalism calculated by:
\begin{equation}
    \expval{A} = \Tr \left(A\rho\right)
\end{equation}
Comparing to the expectation value in the ket notation:
\begin{equation}
    \expval{A}= \sum_i |c_i|^2 \mel{\psi_i}{A}{\psi_i}
\end{equation}
where the sum is over a basis $\{\psi_i\}$. Applying $X = \Tr(\ket{j}X\bra{j})$ and using the cyclic property of the trace, we get:
\begin{align}
    \expval{A}  &= \sum_i \Tr\left(\ket{\psi_j}|c_i|^2 \mel{\psi_i}{A}{\psi_i}\bra{\psi_j}\right) \\
                &= \sum_i \Tr\left(\ket{\psi_i}\bra{\psi_j}\ket{\psi_j}|c_i|^2 \bra{\psi_i}{A}\right) \\
                &=  \Tr\left( \sum_i \ket{\psi_i}|c_i|^2 \bra{\psi_i}{A}\right) \\
                &= \Tr\left(\rho A\right)
\end{align}
Where we recover back to the definition from above if we started with a pure state. 


\subsection{Interactions with the Environment}
The properties of the of the density matrix allows us describe interaction with the environment. Start with considering the product state of two systems:
\begin{equation}
    \rho = \rho_1 \otimes \rho_2
\end{equation}
A measurement in the second system will now have an effect of the product. Measuring system 2 it collapses to $\ket{i}\bra{i}$ with probability $p_i = \rho_{2, ii}$. If we however, have no knowledge of the second system, we would have to average over all the outcomes. This procedure is done by doing a \textit{partial trace} of the scond system. If we define the whole system as $\rho_{\text{total}} = \sum_{ijkl}\rho_{ijkl}\ket{i}\bra{j}\otimes\ket{k}\bra{l}$ \footnote{Often we will represent the four-index density matrix as a two dimensional by concatenating the dimensions. In this representation the four indices can be understood as indexes for block matrices. The $i, k$ indexes block matrices and $j, l$ takes the element from the given block matrix.}, tracing out system 2 would be written:
% A measurement in the second system will collapse the fwith probability $p_i = \rho_{2, ii}$ collapse to $\ket{i}\bra{i}$ state. Averaging over these outcomes with their corresponding probability is obtained by doing a \textit{partial trace}. Writing the total density matrix, defined with four indicies: $\rho_{\text{total}} = \sum_{ijkl}\rho_{ijkl}\ket{i}\bra{j}\otimes\ket{k}\bra{l}$ \footnote{Often we will represent the four-index density matrix as a two dimensional by concatenating the dimensions. In this representation the four indices can be understood as indexes for block matrices. The $i, k$ indexes block matrices and $j, l$ takes the element from the given block matrix.}, tracing out system 2 would be written:
\begin{align}
    \Tr_2 (\rho_{\text{total}})   &= \Tr_2 \left(\sum_{ijkl} \rho_{ijklæ} \ket{i}\bra{j} \otimes \ket{k}\bra{l}\right) \nonumber \\
                                    &= \sum_{ij}\sum_{kl} \rho_{ijkl} \ket{i}\bra{j} \otimes \sum_m \bra{m}  \ket{k}\bra{l}\ket{m} \nonumber \\
    &= \sum_{ijm} \rho_{ijmm} \ket{i}\bra{j}
\end{align}
If we again consider the state $\ket{\rho_+}$ from eq. $\ref{eq:phi_plus}$ but only have control of the first two level system, then our effective density matrix, would be found as:\footnote{effectively we keep all the terms of the first part of the Hilbert space where the second part is the same}
\begin{align}
    \rho_{1, eff}   &= \Tr_2 \left(\frac12 \left(\ket{00}\bra{00} + \ket{00}\bra{11} + \ket{11}\bra{00} + \ket{11}\bra{11} \right) \right) \\
                    &= \frac12 \left(\ket{0}\bra{0} + \ket{1}\bra{1} \right)
\end{align}
This matrix can not be decomposed into a single ket state and is a mixed state. We could also have checked this by seeing $\Tr(\rho^2) = \frac12\neq1$ \cite{manzano_short_2020}. 
 
\subsection{Quantum Maps}
Allowing for loss of entanglement information in a quantum process, we can relax the unitary requirement which came from conserving the inner product of our state vector. Instead we require the mapping of a density matrix to take it into another density matrix:
\begin{equation}
    \Lambda(\rho) \to \rho'
\end{equation}
For it to have the desired physical properties, we want it to be a complete positive (CP) map, such that $\rho_{ii} \geq 0$ for all $i$. This requirement ensures that a map can not map a density matrix to something with negative probabilities. A CP map can be shown to have a representation of the type \cite{greenbaum_introduction_2015}:
\begin{equation}\
    \Lambda(\rho) = \sum_\alpha K_\alpha\rho K_\alpha^\dagger
\end{equation}
where $K_\alpha$ is an operator in our Hilbert space of interest\footnote{Which does not have to be Hermitian, Unitary or invertible.}. This representation is called the Kraus representation and $K_\alpha$ are called the Kraus operators. A further requirement for mapping density matrices to density matrices is that $\Tr
(\rho) = \Tr(\rho') = 1$. Thus the second requirement to a mapping is that it is trace preserving (TP). This is fulfilled if\footnote{This is seen when writing $1 = \Tr(\rho') = \Tr\left(\sum_\alpha K_\alpha\rho K_\alpha^\dagger \right) = \sum_\alpha\Tr\left(K_\alpha\rho K_\alpha^\dagger \right)= \sum_\alpha\Tr\left(K_\alpha^\dagger K_\alpha\rho  \right) = \Tr\left(\sum_\alpha K_\alpha^\dagger K_\alpha\rho  \right)$ which is true if $\sum_\alpha K_\alpha^\dagger K_\alpha = \mathbb{1}$.}:
\begin{equation}
    \sum_\alpha K_\alpha^\dagger K_\alpha = \mathbb{1}
\end{equation}
Thus a physical quantum map is mathematically is one that is CPTP (complete positive trace preserving). \cite{greenbaum_introduction_2015}

\section{Time Evolution of Density Matrices} \label{sec: Time Evolution}
As mentioned in section \ref{sec:scroedinger}, the time-evolution of a quantum state follows the Schrödinger equation: $i\partial_t\ket{\psi(t)} = H\ket{\psi(t)}$. This equation can (for time indepedant Hamiltonians) be solved with the time evolution operator $\unitary(t) = \exp(-iHt)$ to get $\ket{\psi(t)} = \unitary(t)\ket{\psi(0)}$. With this fact, the time dependence of a density matrix subject to a Hamiltonian is found by:
\begin{align}
    \rho(t) &= \sum_{ij} \ket{\psi_i(t)}\bra{\psi_j(t)} = \sum_{ij} \unitary(t) \ket{\psi_i(0)}\bra{\psi_j(0)} \unitary^\dagger(t) \nonumber \\
    &= \unitary(t) \rho(0) \unitary^\dagger(t)
\end{align}
And the derivative:
\begin{align}
    \partial_t \rho(t) &= (\partial_t \unitary(t)) \rho(0)\unitary^\dagger(t) + \unitary(t)\rho(0)(\partial_t \unitary^\dagger) \nonumber \\
    &= -iH \rho(t) +i \rho(t) H \nonumber \\
    &= - i \comm{H}{\rho(t)}
\end{align}
is the differential equation for unitary evolution of a density matrix \cite{manzano_short_2020}. This differential equation would behave if it did not interact with the environment. We can however make it more general.

\subsection{Random Unitary Transformation} \label{sec:random_unitary_transformation}
Before going into the derivation, we will consider an example where we have an interaction with the environment that alters the dynamics of our system. The environment randomly adds a white noise term to the Hamilton which applies some hermitian operator $\theta G$ where $\theta$ is a normally distributed variable with variance $\lambda \Delta t$. This leads to a unitary transformation of $e^{-i\theta}$ over a small time step . When now taking the limit to an infinitesimal time step, $\Delta t \to dt$, the probability density function of $\theta$ is given by:
\begin{equation}
    P(\theta) d\theta = \frac{d\theta}{\sqrt{4\pi\lambda dt}}\exp(-\frac{\theta^2}{4\lambda dt})
\end{equation}
Since the contribution is random, we average over all the possibilities. To first order in $dt$, this leads to the following differential equation:
\begin{fullwidth}
\begin{align}
    \rho(t+dt)  &= \int_\infty^\infty d\theta P(\theta) e^{-iG\theta}\rho(t)e^{iG\theta}  \nonumber \\
                &= \int_\infty^\infty d\theta P(\theta) (1 - iG\theta  - \frac12 G^2\theta^2 \dots)\rho(t) (1 + iG\theta - \frac12 G^2\theta^2 \dots)  \nonumber \\
                &= \int_\infty^\infty d\theta P(\theta) \left(\rho_t - \frac12\theta^2(G^2\rho(t) + \rho(t)G^2 - 2 G\rho(t) G\right) + \mathcal{O}(dt^{3/2}) \nonumber \\
    d\rho(t)    &=  - \frac{\lambda dt}{2} \left(G^2\rho(t) + \rho(t)G^2 - 2 G\rho(t) G\right) \label{eq:lindblad_example}
\end{align}
\end{fullwidth}
where we in the third line used, that $\theta P(\theta)$ is odd and its integral $0$ while the integral of $\int d\theta P(\theta) \theta^2 = \lambda dt$. Equation \ref{eq:lindblad_example} is our first encounter with a time evolution of a Lindblad form. In section \ref{sec:qubit_lindblad} we will look at qubit-environment interactions taking exactly this form, but first we will do a more formal derivation of the Lindblad Master Equation \cite{pearle_simple_2012}.

\subsection{Lindblad Master Equation}
In the above examples, we have shown how unitary or a random unitary transformation looks in the Lindblad form. The Lindblad Master Equation generalizes both of these examples. We will here assume that the Lindblad equation follows a CPTP map, and by doing a Markovian assumption, a proper choice of Krauss operators will lead us to the form. The derivation here follows the methods described by Preskill in \cite{preskill_lecture_chap_3}.

If we consider a system that weakly interacts with an environment such that information leaving the system happens at a much slower rate than the environment resets itself. In our case this means that information that exits the system is lost and cannot reenter the system. The dynamics of our system is then just dependent on the current state and the general parameters of the environment which is just modelled as a bath. By only considering the current state of the system and neglecting the history of states is the Markovian assumption. Using this assumption, the time evolution from a state to the state $dt$ later is a CPTP map: \todo{Not best formulation}
\begin{equation}
    \rho(t + dt) = \Lambda[\rho(t)]
\end{equation}
For a small time step $dt$, we can consider the map to be linear in $dt$.
\begin{equation}
    \Lambda(\rho) = \rho + dt \lindbladian[\rho]
\end{equation}
Where the Lindbladian $\lindbladian[\rho]$ is the \textit{super-operator}\footnote{A super operator refers to an operator acting on a density matrix. It can be some combination of applying operators from both left and right.} of interest since it gives us the differential equation:
\begin{equation}
    d\rho(t) = \lindbladian [\rho(t)] dt
\end{equation}
% Where the map $\lindbladian$ is called the Lindbladian. \footnote{Like the Hamiltonian we can solve this system by applying this operation many times: $\rho(t) = \lim_{n\to \infty} (\identity + \lindbladian t/n)^n\rho(t =0 )$ which can be written as an exponential: $\exp(\lindbladian t)\rho(t = 0)$} To find the lindbladian, we write out the map $\Lambda$ in the Krauss representation:
To find a representation of $\lindbladian$, we can write out the $\Lambda$ in the Krauss representation:
\begin{equation}\label{eq:mapping_comparison}
    \rho(t + dt) = \Lambda[\rho(t)] = \rho(t) + dt \lindbladian[\rho(t)] = \sum_\alpha M_\alpha \rho(t) M_\alpha^\dagger \
\end{equation}
We can now choose a representation of the matrices $M_\alpha$. To retrieve the results from sections \ref{sec: Time Evolution} and \ref{sec:random_unitary_transformation} whilst keeping the form as general as possible, we pick the operators:
\begin{align}
    M_0 &= \identity + (-iH + K)dt \\
    M_\alpha &= \sqrt{dt} L_\alpha \quad \alpha \geq 0
\end{align}
Where $H, K$ are hermitian and $H, K, L_\alpha$ are independent of $dt$. Further introducing the trace preserving condition for the map and keeping terms to first order in $dt$, we find:
\begin{fullwidth}
\begin{align}
    \identity &= \sum_\alpha M_\alpha M_\alpha^\dagger = \left(\identity + (-iH + K)dt\right)\left(\identity + (iH + K)dt\right) + dt \sum_{\alpha \geq 1} L_\alpha L_\alpha^\dagger \\
    &= \identity + dt \left(2K +  \sum_{\alpha\geq 1} L_\alpha L_\alpha^\dagger\right) + \mathcal{O}(dt^2) 
\end{align}
\end{fullwidth}
Which only holds for:
\begin{equation}
    K = - \frac12 \sum_a L_a L_a^\dagger
\end{equation}
where $a$ is reindexing of $\alpha$ by $a = \alpha - 1$. Introducing this back in Eq. \ref{eq:mapping_comparison} 
\begin{fullwidth}
\begin{align}
    \rho(t) + dt \lindbladian &= \left(\identity + (-iH + K)dt\right)\rho(t)\left(\identity + (iH + K)dt\right) + dt \sum_{\alpha \geq 1} L_\alpha \rho(t) L_\alpha^\dagger \\
    &= \rho(t) + dt \left(-i H \rho(t) + iH \rho(t)\right) + dt \left(\sum_a L_a \rho(t) L_a^\dagger + K \rho(t) + \rho(t) K\right) + \mathcal{O}(dt^2) \\
    &= \rho(t) -i dt[H, \rho(t)] + dt \sum_a \left(L_a \rho(t) L_a^\dagger - \frac12 L_a L_a^\dagger \rho(t) - \frac12 \rho(t)L_a L_a^\dagger  \right) + \mathcal{O}(dt^2)
\end{align}
\end{fullwidth}
We now arrive at the final form of the Lindblad Master Equation:
\begin{fullwidth}
\begin{equation}\label{eq:lindblad_master_equation}
    \dot{\rho}(t) = \lindbladian[\rho] = -i dt[H, \rho(t)] +  dt \sum_a \left(L_a \rho(t) L_a^\dagger - \frac12 L_a L_a^\dagger \rho(t) - \frac12 \rho(t)L_a L_a^\dagger  \right)
\end{equation}
\end{fullwidth}
While this is a purely mathematical construction, the naming of variables should indicate the physics in the equation. The $H$ is of course the Hamiltonian and the equation reduces to the unitary evolution if we set all $L_\alpha = 0$. The ${L_\alpha}$ are called Lindblad operators and can be interpreted as decoherence of or dissipation from the system. If we were to set $L_0 = \sqrt{\lambda} G$ and $L_\alpha$ for $\alpha \neq 0$, we recover the random unitary transformation which we saw in \ref{sec:random_unitary_transformation} \cite{preskill_lecture_notes}.

\subsection{Numerical Lindblad Master Equation}
To solve the Lindblad equation numerically, we need it in a form solve able by the methods covered in section \ref{sec:numerical_implementations}. To numerical integrate the equation, the Qutip library reformulates the equations to the super operator formalism \cite{johansson_qutip_2012}. The general idea is to represent a density matrix as a vector by concatenating the axis. By representing the density matrices as (very long) vectors, the super operators can be represented as a matrix\footnote{This is much deeper topic one could use to look at the properties of quantum maps. In this thesis, we just use it to make suitable numerical contribution, so the small introduction will have to suffice. }. With this formulation, we again achieve a linear differential equation with a matrix multiplied by vectors which is convenient to implement. Since we also need to keep track of the coherences of the density matrix, the size of the vectors are now $n^2$ and matrices $n^2\times n^2$. In conclusion, the Lindblad Master Equation can be solved just like the Schrödinger equation, but we will now have a much larger space to keep track off. 

\subsection{Monte Carlo Approximation ** }\label{sec:monte_carlo}
While the Lindblad Equation is a very strong mathematical tool for describing quantum mechanics, numerically simulating it scales heavily with the size of our hilbert space. Another approximation is do a Monte Carlo Approximation. Since the Lindblad operators \todo{Make sure the reader knows this} $\sqrt{\gamma}L$ happen with the rate $\gamma$ we can instead of simulating the whole density matrix simulate the state vector many times and at every time step apply the Lindblad operator with probability $\gamma dt$. In between application of the Lindblad Operators the system will just be integrated by the normal schödinger equation.\todo{This is actually more sophisticated, the time of the collapse is chosen from the distribution and we integrate to that point. } One can then take the average over either the states or the expectation values of interest.\cite{qutip}

\section{Dissipation and Decoherence in Qubits} \label{sec:qubit_lindblad}
We will now take a look, at how the decoherence show in the qubits and in the resonators. While a lot of interesting physics is associated with the interaction with the environment, we will with the Lindblad equation at hand only look at the qubit-resonator system as an open system and consider the environment unchangeable. With this, we will focus in particular on a few parameters describing the interaction: the temperature $T$, characteristic time of qubit decay $T_1$ characteristic time of qubit dephasing $T_2$ and lastly the rate of photon decay from the resonator $\kappa$.

\subsection{Density Matrix of a Qubit}
First, it will be beneficial to expand the representation of a qubit to its density matrix. If we take an arbitrary two level state as described in section \ref{sec:tls}, we find an example of a pure state density matrix by just taking its product with itself: $\ket{\psi} = \cos (\theta / 2) \ket{0} + e^{i\phi}\sin(\theta / 2)\ket{1}$
% \begin{fullwidth}
\begin{align}
    \rho_{\text{qubit}} = \ket{\psi}\bra{\psi} &= \begin{pmatrix}
        \cos^2(\theta/2)                        & e^{-i\phi}\cos(\theta/2)\sin(\theta/2) \\
        e^{i\phi}\cos(\theta/2)\sin(\theta/2)  & \sin^2(\theta/2)
    \end{pmatrix} \nonumber \\
    &= \frac12 + \begin{pmatrix}
        \cos(\theta)                       & e^{-i\phi}\sin(\theta) \\
        e^{i\phi}\sin(\theta)  & -\cos(\theta)   
    \end{pmatrix} \nonumber \\
    &= \frac12 (\identity + \Vec{a} \cdot \Vec{\sigma}) \label{eq:density_of_qubit}
\end{align}
% \end{fullwidth}
Where $\Vec{\sigma} = [\sigma_x, \sigma_y, \sigma_z]$ and $\Vec{a} = [\sin{\theta}\cos{\phi}, \sin{\theta}\sin{\phi}, \cos{\theta}]$ is the coefficients\cite{krantz_quantum_2019}.  The resemblance to Cartesian coordinates allow us to think about $\Vec{a}$ as vector pointing to the state.

\begin{marginfigure}[-11 cm]
    \centering
    \includegraphics[]{Figs/Theory/bloch_sphere_pure.pdf}
    \includegraphics[]{Figs/Theory/bloch_sphere_mixed.pdf}
    \caption{Pure state (top) and mixed state (bottom) visualized on the Bloch Sphere.}
    \label{fig:bloch_sphere_density_matrix}
\end{marginfigure}

The representation in equation \ref{eq:density_of_qubit} provides even more flexibility. When we have a pure state, $|\Vec{a}| = 1$, and the vector points to the unit sphere. However $\rho = \frac12 \; \identity$ is also a valid density matrix, namely the fully mixed matrix. Here $|\Vec{a}|=0$. In terms of the Bloch sphere, we can think of pure states as living on the surface while mixed states will have an associated vector pointing somewhere inside $|\Vec{a}|<1\Leftrightarrow \Tr(\rho^2) < 1$.

\subsection{The Temperature of the System}
Even at low temperatures, one should expect to see the temperature have an effect on the qubit. If we consider it part of its environment, statistical physics would indicate, that the qubit is distributed due to Boltzmann statistics. Limiting us self to a two level system, we would find the qubit in $\ket{0}$ with $\text{prob}(\ket{0}) = 1 / (1 + e^{-\beta\omega_{01}})$ and $\text{prob}(\ket{1}) = e^{-\beta\omega_{01}} / (1 + e^{-\beta\omega_{01}}).$ While the idea is to initialize the qubit in $\ket{0}$, this fact means that waiting until equilibrium our qubit would be in \cite{statphys?}:
\begin{equation}\label{eq:equilibrium_qubit_density_matrix}
    \rho_{\text{equilibrium}} = \frac{1}{1 + e^{-\beta\omega_{01}}}\begin{pmatrix}
        1 & 0 \\
        0 & e^{-\beta\omega_{01}}
    \end{pmatrix}
\end{equation}

\subsection{Longitudinal Relaxation}\label{sec:theory_t1}
If the qubit exchanges energy with the environment it could drive transitions between the states $\ket{1} \leftrightarrow \ket{0}$. The relaxation from $\ket{0}\to\ket{1}$ at a rate $\Gamma_\downarrow$ will in the Lindblad equation be described by the Lindblad operator $L_{\downarrow} = \sqrt{\Gamma_{\downarrow}} \ket{0}\bra{1}$ and correspondingly $L{_\uparrow} = \sqrt{\Gamma_{\uparrow}} \ket{1}\bra{0}$ will describe the excitement. A qubit which relaxes energy into the environment will have time dynamics which follows\footnote{We use here the anti-commutator $\{A, B\} = AB + BA$ to write the Lindbladian a bit more compactly}: 
\begin{align*}
    \dot{\rho}(t) &= \mathcal{D}[L_{\downarrow}]\rho(t)) \\
    \dot{\rho}(t) &= \Gamma_\downarrow\left(\ket{0}\bra{1} \rho(t) \ket{1}\bra{0} - \frac12 \{\ket{1}\bra{0}\ket{0}\bra{1}, \rho(t)\}\right) \\
    \dot{\rho}(t) &= \Gamma_\downarrow\left(\rho_{11}\ket{0}\bra{0} - \rho_{11} \ket{1}\bra{1} - \frac12\left(\rho_{01}\ket{1}\bra{0} + \rho_{10}\ket{0}\bra{1}\right)\right)
\end{align*}
By looking at the individual components of the density matrix, we find:
\begin{align*}
    &\dot{\rho}_{00}(t) = \Gamma_\downarrow\rho_{11}(t)  &\dot{\rho}_{10}(t) = -\frac12\Gamma_\downarrow\rho_{10}(t)\; \\   
    &\dot{\rho}_{01}(t) = \frac12 \Gamma_\downarrow\rho_{01}(t)   &\dot{\rho}_{11}(t) = -\Gamma_\downarrow\rho_{11}(t)\;
\end{align*}
% \end{align*}
When adding the contribution from $\mathcal{D}[L_\uparrow]\rho(t)$ and introducing $\Gamma_1 = \Gamma_\downarrow + \Gamma_\uparrow$, we find the diagonal elements to:
\begin{equation}
    \dot{\rho}_{00}(t) = \Gamma_\downarrow\rho_{11}(t) - \Gamma_\uparrow\rho_{00}(t), \quad \dot{\rho}_{11}(t) = \Gamma_\uparrow\rho_{00}(t)-\Gamma_\downarrow\rho_{11}(t)\; \\   
\end{equation}
and the off-diagonal to:
\begin{equation}
    \dot{\rho}_{01}(t) = -\frac12 \Gamma_1\rho_{01}(t),  \quad \dot{\rho}_{10}(t) = -\frac12\Gamma_1\rho_{10}(t) \;
\end{equation}
The diagonal elements make up a set of coupled differential equation, solving for these two\footnote{This is done by writing the differential equation in matrix representation, by diagonalizing the coefficient we find a basis were the differential equation are decoupled. Solving here and returning to back gives the solution. }  and using $\Tr(\rho) = \rho_{00} + \rho_{11} = 1$ gives:
\begin{equation}
\rho_{00}(t) = \frac{\Gamma_\downarrow}{\Gamma_\uparrow + \Gamma_\downarrow} + \left(\rho_{00}(t=0) -  \frac{\Gamma_\downarrow}{\Gamma_\uparrow + \Gamma_\downarrow}\right)e^{-t(\Gamma_\uparrow + \Gamma_\downarrow)}
\end{equation}
and 
\begin{equation}    
\rho_{11}(t) = \frac{\Gamma_\uparrow}{\Gamma_\uparrow + \Gamma_\downarrow}+\left( \rho_{11}(t=0) -\frac{ \Gamma_\uparrow}{\Gamma_\uparrow + \Gamma_\downarrow}\right) e^{-t(\Gamma_\uparrow + \Gamma_\downarrow)}
\end{equation}
while the off-diagonals are simply solved by exponential decay:
\begin{equation}
    \rho_{01}(t) = e^{-\Gamma_1 t/2}\rho_{01}(t=0), \quad \rho_{10}(t) = e^{-\Gamma_1 t/2}\rho_{10}(t=0)
\end{equation}
From this we see the effects of energy exchange: excitations and relaxations effect the occupation of $\ket{0}$ and $\ket{1}$ until they are in an equilibrium. Further, the energy exchange also leads to decoherence on the diagonal with a rate of $\Gamma_1/2$. 
\begin{marginfigure}
    \centering
    \missingfigure{T1 Figure}
    \caption{Caption}
    \label{fig:enter-label}
\end{marginfigure}
We can also compare the equilibrium position $t\to\infty$ with the equilibrium state described by the Boltzmann statistics in equation \ref{eq:equilibrium_qubit_density_matrix}. Here we find that the rates should satisfy:
\begin{equation}
    \frac{\Gamma_\downarrow}{\Gamma_\uparrow + \Gamma_\downarrow} = \frac{1}{1 + e^{-\beta\omega_{01}}} \Rightarrow \frac{\Gamma_\uparrow}{\Gamma_\downarrow} =e^{-\beta\omega_{01}} 
\end{equation}
For low temperaturs $\beta \omega_{01} \ll 1$, this means that $\Gamma_1 \approx \Gamma_\downarrow$. The characteristic time of the decay from an arbitrary density matrix to the equilibrium is described by the characteristic time $T_1 = \frac{1}{\Gamma_1}$.

\subsection{Dephasing}\label{sec:theory_t2}
If the environment connect to the energy splitting and alters it, the we will experience dephasing of the qubit. Mostly, dephasing is split into two parts: 

\textbf{A slow part} that compared to the experiment we run, such that we can consider it a constant shift of the qubit frequency $\omega \to \omega + \delta_\omega$. We can look at the consequences of this by simply evolving the equations unitarily. 

% \begin{marginfigure}
%     \centering
%     \missingfigure{Slow dephasing}
%     \missingfigure{Fast dephasing}
%     \caption{Caption}
%     \label{fig:enter-label}
% \end{marginfigure}

\textbf{A faster part} which changes multiple times during the experiment. If we consider this a normal distributed contribution to $\sigma_z$ at each small timestep, we can model this like the random unitary example, we considered in section \ref{sec:random_unitary_transformation} in which we would have the operator $L_\phi = \sqrt{\Gamma_\phi}\sigma_z$. If we apply this Lindblad operator, the time evolution would look like:
\begin{equation}
    \dot{\rho}(t) = \mathcal{D}[L_{\phi}]\rho(t)) = \Gamma_\phi\left(\sigma_z \rho(t) \sigma_z -\frac12( \sigma_z^2 \rho(t) + \rho(t) \sigma_z^2)\right)
\end{equation}
Since $\sigma_z^2 = \identity$ and $\sigma_z \rho(t) \sigma_z$ flips the sign of the diagonals, we get:
\begin{equation}
    \dot{\rho}(t) = - \Gamma_\phi \left(\ket{0}\bra{1}\rho_{01} - \ket{0}\bra{1}\rho_{01}\right)
\end{equation}
Thus giving us an extra contribution to the decoherence terms, which are simply solved by:
\begin{equation}
    \rho_{01}(t) = e^{-\Gamma_\phi t}\rho_{01}(t=0), \quad \rho_{10}(t) = e^{-\Gamma_\phi t}\rho_{10}(t=0)
\end{equation}
So if were to combine the decays from this section and the last, the total dephasing rate would come out to be:
\begin{equation}
    \Gamma_2 = \Gamma_\phi + \frac12\Gamma_1 
\end{equation}
This is often described by the characteristic time of decoherence:
\begin{equation}\label{eq:t2_equation}
    T_2 = \frac{1}{\Gamma_2} = \frac{1}{\Gamma_\phi + \frac12\Gamma_1 } 
\end{equation}



% note:
% \begin{itemize}
%     \item This can probably be formulated better with the use of "Simple Derivation of the Lindblad Equation" where they introduce the random unitary operator to start phases change . Lindblad operator is $L = \sqrt{\Gamma_\phi}\sigma_z$
%     \item Maybe we can extract this from writing out the random unitary with the $\sigma_z$
% \end{itemize}

% If qubits instead connect longitudinally (along the $z-axis$) they can alter the qubit frequency $\omega_{01}$ which setts us at a disadvantage. Since we normally think about the $x-$ and $y-$axis in the rotating frame with the frequency $\omega_{01}$ any changes to the qubit frequency would speed up / slow down the actual rotation, and ultimately we lose information about the actual phase of the qubit. 

% Since there is no energy exchange with the environment this is a unitary process, and it is theory possible to reverse the effect and place the qubit back in the reference frame we know. However, this would assume that we have complete information about the time-dependence of the effective qubit frequency which is not realistic. With a clever use of gates, we can however decouple the pulse by using dynamical decoupling schemes which we will shortly return to in the section about calibrating the characteristic dephasing time $T_2$. *The concept is simply to apply $X_{\pi}$ pulses frequently to refocus the noise. Thus if some qubit initializations precess faster or slower adding a $X_\pi$ gate would flip the order allowing the fast ones to cast up and the slow ones to fall back to the actual qubit frequency

% The rate of dephasing has two components, one from the stochastic "pure" dephasing time described above. This rate is given as $\Gamma_\phi$. The second contribution comes from energy relaxation since any superposition would lose all phase information once collapsed. Think of the $\frac{1}{\sqrt(2)}\left(\ket{0} + e^{i\phi}\ket{1}\right)$ superposition. If $\ket{1}$ were to decay to $\ket{0}$ the phase of the qubit state would also be lost. The total dephasing rate can be found by:
% $$\Gamma_{2}=\Gamma_\phi+\frac{\Gamma_{1}}{2}$$
% and the characteristic dephasing time is given by:
% $$T_2=\frac{1}{\Gamma_{2}}$$

\subsection{Resonator Decays}\label{sec:resonator_decays}
The coupled resonator also leaks photon to the environment. This happens with a much higher rate since it is directly coupled to the feed line. The output of photon also consist of two parts, unwanted dissipation to the environment and leakage to the feed line which we are able to detect. For photon loss the Lindbladian operator is given by $L = \sqrt{\kappa}a$.

In section \ref{sec:driving_resonator_iq_plane}, we found a differential equation for the pointer state of a coherent state, when we drive the resonator. If we repeat the exercise, but now also consider the Lindbladian term, we get a further addition to the time dependence of $a$ in the Heisenberg picture since it takes the form of $\frac{d}{dt}a(t) = i[H_eff, a(t)] +  \mathcal{D}[\sqrt{\kappa}a]$. Here $\mathcal{D}[\sqrt{\kappa}a]$ is given by:
\begin{equation}
    \mathcal{D}[\sqrt{\kappa}a] = \kappa \left(a^\dagger a a -\frac12 \left(a^\dagger a a + a a^\dagger a \right) \right)
\end{equation}
Using the commutator relation $\comm{a}{a^\dagger} = 1$, this can be reduced to
\begin{equation}
    \mathcal{D}[\sqrt{\kappa}a] = -\frac{1}{2}\kappa a 
\end{equation}
If we reintroduced this into the equations of motion, we would find an additional term in the differential equation for the pointer states:
\begin{equation}\label{eq:resonator_movement}
    \frac{d}{dt}\alpha(t) = - i \left(\omega_r - \omega_d \pm \chi\right) \alpha(t) + i\epsilon - \frac{\kappa}{2}\alpha(t) 
\end{equation}
This dissipative term takes the effect of pushing the coherent state closer to the origin. If we were to repeat the driving of the resonator with the dissipation, we see that driving off resonance gives a spiral instead of circle towards some steady state. These steady state values can also be found by solving for the steady state equation with $\dot{\alpha}(t) = 0$. We find:
\begin{equation}
    \alpha_{\text{ss}} = \frac{-\epsilon}{(\omega_r - \omega_d \pm \chi) - i \kappa / 2}
\end{equation}
From which we can extract the steady state amplitude from equation \ref{eq:steady_state_amplitude}:
\begin{equation}\label{eq:steady_state_amplitude}
    |\alpha_{\text{ss}}| = \frac{\epsilon}{\sqrt{(\omega_r - \omega_d \pm \chi)^2 + \kappa^2 / 4}}
\end{equation}


% One could follow the same calculations and arguments as with the qubit $T_1$ and would find the Lindblad operator $\sqrt{\kappa}a$. Ultimately this also gives a decay of resonator towards its equlibrium which we can assume to be ground state if it is cold enough. The rate $\kappa$ described the rate at which photons escape the resonator.

